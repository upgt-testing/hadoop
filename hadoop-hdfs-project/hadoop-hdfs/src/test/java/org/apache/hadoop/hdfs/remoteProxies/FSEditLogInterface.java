package org.apache.hadoop.hdfs.remoteProxies;

public interface FSEditLogInterface {
    void logRemoveCacheDirectiveInfo(java.lang.Long arg0, boolean arg1);
    void checkForGaps(java.util.List<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> arg0, long arg1, long arg2, boolean arg3) throws java.io.IOException;
    void startLogSegmentAndWriteHeaderTxn(long arg0, int arg1) throws java.io.IOException;
    void waitForSyncToFinish();
    void formatNonFileJournals(NamespaceInfoInterface arg0, boolean arg1) throws java.io.IOException;
    JournalSetInterface getJournalSet();
    void initJournals(java.util.List<java.net.URI> arg0);
    void doFinalizeOfSharedLog() throws java.io.IOException;
    java.util.Collection<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> selectInputStreams(long arg0, long arg1, MetaRecoveryContextInterface arg2, boolean arg3) throws java.io.IOException;
    void startLogSegment(long arg0, boolean arg1, int arg2) throws java.io.IOException;
    void logAddErasureCodingPolicy(ErasureCodingPolicyInterface arg0, boolean arg1);
    void logCreateSnapshot(java.lang.String arg0, java.lang.String arg1, boolean arg2, long arg3);
    void logAddCachePool(CachePoolInfoInterface arg0, boolean arg1);
    void printStatistics(boolean arg0);
    void restart();
    void logUpdateMasterKey(DelegationKeyInterface arg0);
    void logSymlink(java.lang.String arg0, java.lang.String arg1, long arg2, long arg3, INodeSymlinkInterface arg4, boolean arg5);
    long getTotalSyncCount();
    void logSyncAll();
    void logRemoveCachePool(java.lang.String arg0, boolean arg1);
    boolean canRollBackSharedLog(StorageInfoInterface arg0, int arg1) throws java.io.IOException;
    void endCurrentLogSegment(boolean arg0);
    boolean shouldForceSync();
    void logSetQuotaByStorageType(java.lang.String arg0, long arg1, org.apache.hadoop.fs.StorageType arg2);
    void logRenameSnapshot(java.lang.String arg0, java.lang.String arg1, java.lang.String arg2, boolean arg3, long arg4);
    void logModifyCachePool(CachePoolInfoInterface arg0, boolean arg1);
    void logAppendFile(java.lang.String arg0, INodeFileInterface arg1, boolean arg2, boolean arg3);
    void logLegacyGenerationStamp(long arg0);
    void logSetReplication(java.lang.String arg0, short arg1);
    void logSetQuota(java.lang.String arg0, long arg1, long arg2);
    void logCancelDelegationToken(DelegationTokenIdentifierInterface arg0);
    java.util.Collection<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> selectInputStreams(long arg0, long arg1) throws java.io.IOException;
    void logEdit(int arg0, byte[] arg1);
    void startLogSegment(long arg0, int arg1) throws java.io.IOException;
    java.util.Collection<java.net.URI> getEditURIs();
    void initJournalsForWrite();
    java.util.Collection<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> selectInputStreams(long arg0, long arg1, MetaRecoveryContextInterface arg2, boolean arg3, boolean arg4) throws java.io.IOException;
    void logAllocateBlockId(long arg0);
    FSEditLogInterface newInstance(ConfigurationInterface arg0, NNStorageInterface arg1, java.util.List<java.net.URI> arg2);
    void logRename(java.lang.String arg0, java.lang.String arg1, long arg2, boolean arg3);
    void doRollback() throws java.io.IOException;
    void close();
    void logDisallowSnapshot(java.lang.String arg0);
    void logTruncate(java.lang.String arg0, java.lang.String arg1, java.lang.String arg2, long arg3, long arg4, BlockInterface arg5);
    boolean isOpenForWriteWithoutLock();
    void logRemoveXAttrs(java.lang.String arg0, java.util.List<org.apache.hadoop.fs.XAttr> arg1, boolean arg2);
    boolean isOpenForWrite();
    void logEnableErasureCodingPolicy(java.lang.String arg0, boolean arg1);
    long getCurSegmentTxId();
    long getLastWrittenTxIdWithoutLock();
    void logSetAcl(java.lang.String arg0, java.util.List<org.apache.hadoop.fs.permission.AclEntry> arg1);
    long getSyncTxId();
    void logFinalizeRollingUpgrade(long arg0);
    void setJournalSetForTesting(JournalSetInterface arg0);
    void discardSegments(long arg0) throws java.io.IOException;
    void initSharedJournalsForRead();
    void logTimes(java.lang.String arg0, long arg1, long arg2);
    void beginTransaction(FSEditLogOpInterface arg0);
    void doneWithAutoSyncScheduling();
    RemoteEditLogManifestInterface getEditLogManifest(long arg0) throws java.io.IOException;
    void logDisableErasureCodingPolicy(java.lang.String arg0, boolean arg1);
    long getCurSegmentTxIdWithoutLock();
    void doUpgradeOfSharedLog() throws java.io.IOException;
    void logCloseFile(java.lang.String arg0, INodeFileInterface arg1);
    void recoverUnclosedStreams();
    void setOutputBufferCapacity(int arg0);
    void releaseBackupStream(NamenodeRegistrationInterface arg0) throws java.io.IOException;
    void logDeleteSnapshot(java.lang.String arg0, java.lang.String arg1, boolean arg2, long arg3);
    void logSync(long arg0);
    void waitIfAutoSyncScheduled();
    void logRenewDelegationToken(DelegationTokenIdentifierInterface arg0, long arg1);
    void logEdit(FSEditLogOpInterface arg0);
    void logReassignLease(java.lang.String arg0, java.lang.String arg1, java.lang.String arg2);
    void logAddBlock(java.lang.String arg0, INodeFileInterface arg1);
    void abortCurrentLogSegment();
    void endTransaction(long arg0);
    void logConcat(java.lang.String arg0, java.lang.String[] arg1, long arg2, boolean arg3);
    void openForWrite(int arg0) throws java.io.IOException;
    void logRpcIds(FSEditLogOpInterface arg0, boolean arg1);
    void logOpenFile(java.lang.String arg0, INodeFileInterface arg1, boolean arg2, boolean arg3);
    void logDelete(java.lang.String arg0, long arg1, boolean arg2);
    void closeAllStreams(java.lang.Iterable<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> arg0);
    void logGenerationStamp(long arg0);
    boolean isSegmentOpenWithoutLock();
    void doPreUpgradeOfSharedLog() throws java.io.IOException;
    java.util.List<org.apache.hadoop.hdfs.server.common.Storage.FormatConfirmable> getFormatConfirmables();
    java.util.List<org.apache.hadoop.hdfs.server.namenode.JournalSet.JournalAndStream> getJournals();
    void logStartRollingUpgrade(long arg0);
    long getSharedLogCTime() throws java.io.IOException;
    void logModifyCacheDirectiveInfo(CacheDirectiveInfoInterface arg0, boolean arg1);
    boolean isOpenForRead();
    void logSetPermissions(java.lang.String arg0, FsPermissionInterface arg1);
    void logUpdateBlocks(java.lang.String arg0, INodeFileInterface arg1, boolean arg2);
    void logSetStoragePolicy(java.lang.String arg0, byte arg1);
    void purgeLogsOlderThan(long arg0);
    void setMetricsForTests(NameNodeMetricsInterface arg0);
    void logMkDir(java.lang.String arg0, INodeInterface arg1);
    long getLastWrittenTxId();
    void logSetXAttrs(java.lang.String arg0, java.util.List<org.apache.hadoop.fs.XAttr> arg1, boolean arg2);
    void logRemoveErasureCodingPolicy(java.lang.String arg0, boolean arg1);
    void registerBackupNode(NamenodeRegistrationInterface arg0, NamenodeRegistrationInterface arg1) throws java.io.IOException;
    void selectInputStreams(java.util.Collection<org.apache.hadoop.hdfs.server.namenode.EditLogInputStream> arg0, long arg1, boolean arg2, boolean arg3) throws java.io.IOException;
    void logGetDelegationToken(DelegationTokenIdentifierInterface arg0, long arg1);
    boolean isSegmentOpen();
    java.lang.Class<? extends org.apache.hadoop.hdfs.server.namenode.JournalManager> getJournalClass(ConfigurationInterface arg0, java.lang.String arg1);
    void logSetOwner(java.lang.String arg0, java.lang.String arg1, java.lang.String arg2);
    void logAddCacheDirectiveInfo(CacheDirectiveInfoInterface arg0, boolean arg1);
    long rollEditLog(int arg0) throws java.io.IOException;
    void logAllowSnapshot(java.lang.String arg0);
    void logSync();
    void journal(long arg0, int arg1, byte[] arg2);
    org.apache.hadoop.hdfs.server.namenode.JournalManager createJournal(java.net.URI arg0);
    boolean doEditTransaction(FSEditLogOpInterface arg0);
    void setNextTxId(long arg0);
    void logRename(java.lang.String arg0, java.lang.String arg1, long arg2, boolean arg3, org.apache.hadoop.fs.Options.Rename... arg4);
    BackupJournalManagerInterface findBackupJournal(NamenodeRegistrationInterface arg0);
}