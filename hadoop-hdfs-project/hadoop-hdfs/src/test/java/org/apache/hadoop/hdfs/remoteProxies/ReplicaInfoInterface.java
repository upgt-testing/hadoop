package org.apache.hadoop.hdfs.remoteProxies;

public interface ReplicaInfoInterface {
    long getGenerationStamp();
    ReplicaRecoveryInfoInterface createInfo();
    java.lang.String getBlockName();
    java.io.File metaToBlockFile(java.io.File arg0);
    void copyMetadata(java.net.URI arg0) throws java.io.IOException;
    void updateWithReplica(StorageLocationInterface arg0);
    long getBytesOnDisk();
    void setGenerationStamp(long arg0);
    boolean isMetaFilename(java.lang.String arg0);
    int compareWith(ScanInfoInterface arg0);
    long getGenerationStamp(java.lang.String arg0);
    java.net.URI getBlockURI();
    boolean matchingIdAndGenStamp(BlockInterface arg0, BlockInterface arg1);
    boolean renameMeta(java.net.URI arg0) throws java.io.IOException;
    boolean deleteBlockData();
    long getMetadataLength();
    boolean blockDataExists();
    java.io.OutputStream getDataOutputStream(boolean arg0) throws java.io.IOException;
    java.lang.String getStorageUuid();
    void setRecoveryID(long arg0);
    void set(long arg0, long arg1, long arg2);
    long getBytesReserved();
    void copyBlockdata(java.net.URI arg0) throws java.io.IOException;
    int compareTo(BlockInterface arg0);
    java.net.URI getMetadataURI();
    boolean isBlockFilename(java.io.File arg0);
    void readHelper(java.io.DataInput arg0) throws java.io.IOException;
    void setVolume(org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi arg0);
    ReplicaInfoInterface getOriginalReplica();
    org.apache.hadoop.util.LightWeightGSet.LinkedElement getNext();
    boolean breakHardLinksIfNeeded() throws java.io.IOException;
    java.lang.String toString(BlockInterface arg0);
    boolean getPinning(LocalFileSystemInterface arg0) throws java.io.IOException;
    boolean isOnTransientStorage();
    void setBlockId(long arg0);
    long getRecoveryID();
    boolean renameData(java.net.URI arg0) throws java.io.IOException;
    void truncateBlock(long arg0) throws java.io.IOException;
    int hashCode();
    void appendStringTo(java.lang.StringBuilder arg0);
    void setNumBytes(long arg0);
    long getBlockDataLength();
    java.io.InputStream getDataInputStream(long arg0) throws java.io.IOException;
    void write(java.io.DataOutput arg0) throws java.io.IOException;
    FileIoProviderInterface getFileIoProvider();
    org.apache.hadoop.hdfs.server.datanode.fsdataset.FsVolumeSpi getVolume();
    long filename2id(java.lang.String arg0);
    long getBlockId();
    void setNext(org.apache.hadoop.util.LightWeightGSet.LinkedElement arg0);
    java.lang.String toString();
    LengthInputStreamInterface getMetadataInputStream(long arg0) throws java.io.IOException;
    void bumpReplicaGS(long arg0) throws java.io.IOException;
    boolean deleteMetadata();
    long getOriginalBytesReserved();
    void readId(java.io.DataInput arg0) throws java.io.IOException;
    org.apache.hadoop.hdfs.server.common.HdfsServerConstants.ReplicaState getState();
    long getNumBytes();
    java.io.OutputStream getMetadataOutputStream(boolean arg0) throws java.io.IOException;
    long getVisibleLength();
    void writeId(java.io.DataOutput arg0) throws java.io.IOException;
    void setPinning(LocalFileSystemInterface arg0) throws java.io.IOException;
    void readFields(java.io.DataInput arg0) throws java.io.IOException;
    long getBlockId(java.lang.String arg0);
    boolean equals(java.lang.Object arg0);
    void writeHelper(java.io.DataOutput arg0) throws java.io.IOException;
    boolean metadataExists();
}