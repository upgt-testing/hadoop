package org.apache.hadoop.hdfs.remoteProxies;

public interface DescriptorProtoInterface {
    BuilderInterface toBuilder();
    int getSerializedSize();
    java.lang.Object getField(FieldDescriptorInterface arg0);
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ReservedRangeOrBuilder getReservedRangeOrBuilder(int arg0);
    void writeTo(CodedOutputStreamInterface arg0) throws java.io.IOException;
    byte[] toByteArray();
    java.lang.Object writeReplace() throws java.io.ObjectStreamException;
    java.util.List<java.lang.String> findInitializationErrors();
    OneofDescriptorProtoInterface getOneofDecl(int arg0);
    boolean compareMapField(java.lang.Object arg0, java.lang.Object arg1);
    ByteStringInterface getReservedNameBytes(int arg0);
    int getExtensionCount();
    java.lang.String getInitializationErrorString();
    DescriptorProtoInterface parseDelimitedFrom(java.io.InputStream arg0) throws java.io.IOException;
    EnumDescriptorProtoInterface getEnumType(int arg0);
    org.apache.hadoop.thirdparty.protobuf.MessageLite.Builder newBuilderForType();
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProtoOrBuilder getExtensionOrBuilder(int arg0);
    org.apache.hadoop.thirdparty.protobuf.Parser<? extends org.apache.hadoop.thirdparty.protobuf.Message> getParserForType();
    boolean compareBytes(java.lang.Object arg0, java.lang.Object arg1);
//    BuilderInterface newBuilderForType(org.apache.hadoop.thirdparty.protobuf.GeneratedMessageV3.BuilderParent arg0);
    org.apache.hadoop.thirdparty.protobuf.MessageLite getDefaultInstanceForType();
    DescriptorProtoInterface parseFrom(java.io.InputStream arg0) throws java.io.IOException;
    DescriptorProtoInterface parseFrom(java.nio.ByteBuffer arg0, ExtensionRegistryLiteInterface arg1) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProto> getExtensionList();
    DescriptorProtoInterface parseFrom(java.io.InputStream arg0, ExtensionRegistryLiteInterface arg1) throws java.io.IOException;
    DescriptorProtoInterface parseDelimitedFrom(java.io.InputStream arg0, ExtensionRegistryLiteInterface arg1) throws java.io.IOException;
    int getNestedTypeCount();
    int getFieldCount();
    int computeStringSizeNoTag(java.lang.Object arg0);
    BuilderInterface newBuilder();
    org.apache.hadoop.thirdparty.protobuf.Internal.DoubleList newDoubleList();
    void makeExtensionsImmutable();
    BuilderInterface newBuilder(DescriptorProtoInterface arg0);
//    org.apache.hadoop.thirdparty.protobuf.Parser<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto> getParserForType();
    void writeTo(java.io.OutputStream arg0) throws java.io.IOException;
    void setMemoizedSerializedSize(int arg0);
    int getReservedRangeCount();
    org.apache.hadoop.thirdparty.protobuf.Internal.IntList mutableCopy(org.apache.hadoop.thirdparty.protobuf.Internal.IntList arg0);
    <V> void maybeSerializeBooleanEntryTo(CodedOutputStreamInterface arg0, java.util.Map<java.lang.Boolean, V> arg1, MapEntryInterface<java.lang.Boolean, V> arg2, int arg3, boolean arg4) throws java.io.IOException;
    <M> M parseDelimitedWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, java.io.InputStream arg1, ExtensionRegistryLiteInterface arg2) throws java.io.IOException;
    java.util.Map convertMapEntryListToMap(java.util.List arg0);
    org.apache.hadoop.thirdparty.protobuf.Internal.IntList emptyIntList();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ReservedRangeOrBuilder> getReservedRangeOrBuilderList();
    <V> void serializeBooleanMapTo(CodedOutputStreamInterface arg0, MapFieldInterface<java.lang.Boolean, V> arg1, MapEntryInterface<java.lang.Boolean, V> arg2, int arg3) throws java.io.IOException;
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProtoOrBuilder> getExtensionOrBuilderList();
    boolean hasOptions();
//    org.apache.hadoop.thirdparty.protobuf.Parser<? extends org.apache.hadoop.thirdparty.protobuf.GeneratedMessageV3> getParserForType();
    org.apache.hadoop.thirdparty.protobuf.Internal.BooleanList newBooleanList();
    <V> void serializeStringMapTo(CodedOutputStreamInterface arg0, MapFieldInterface<java.lang.String, V> arg1, MapEntryInterface<java.lang.String, V> arg2, int arg3) throws java.io.IOException;
    int computeStringSize(int arg0, java.lang.Object arg1);
    java.lang.String toString();
    boolean equals(java.lang.Object arg0);
    ExtensionRangeInterface getExtensionRange(int arg0);
    int hashBoolean(boolean arg0);
    int getRepeatedFieldCount(FieldDescriptorInterface arg0);
    <T> void addAll(java.lang.Iterable<T> arg0, java.util.List<? super T> arg1);
    java.lang.String getReservedName(int arg0);
    void writeStringNoTag(CodedOutputStreamInterface arg0, java.lang.Object arg1) throws java.io.IOException;
    java.util.List<java.lang.String> getReservedNameList();
    FieldDescriptorProtoInterface getExtension(int arg0);
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto> getNestedTypeList();
    boolean parseUnknownFieldProto3(CodedInputStreamInterface arg0, BuilderInterface arg1, ExtensionRegistryLiteInterface arg2, int arg3) throws java.io.IOException;
    boolean hasName();
    java.lang.String getName();
//    BuilderInterface newBuilderForType();
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.EnumDescriptorProto> getEnumTypeList();
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ReservedRange> getReservedRangeList();
    void checkByteStringIsUtf8(ByteStringInterface arg0) throws java.lang.IllegalArgumentException;
    int getMemoizedSerializedSize();
    org.apache.hadoop.thirdparty.protobuf.Internal.BooleanList mutableCopy(org.apache.hadoop.thirdparty.protobuf.Internal.BooleanList arg0);
    java.lang.Object getFieldRaw(FieldDescriptorInterface arg0);
    DescriptorProtoInterface parseFrom(ByteStringInterface arg0) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
    DescriptorProtoInterface parseFrom(CodedInputStreamInterface arg0) throws java.io.IOException;
    void enableAlwaysUseFieldBuildersForTesting();
    <V> void serializeLongMapTo(CodedOutputStreamInterface arg0, MapFieldInterface<java.lang.Long, V> arg1, MapEntryInterface<java.lang.Long, V> arg2, int arg3) throws java.io.IOException;
//    org.apache.hadoop.thirdparty.protobuf.Parser<? extends org.apache.hadoop.thirdparty.protobuf.MessageLite> getParserForType();
    boolean isInitialized();
    ByteStringInterface toByteString();
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.MessageOptionsOrBuilder getOptionsOrBuilder();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.EnumDescriptorProtoOrBuilder> getEnumTypeOrBuilderList();
    org.apache.hadoop.thirdparty.protobuf.Internal.DoubleList emptyDoubleList();
    DescriptorProtoInterface parseFrom(byte[] arg0, ExtensionRegistryLiteInterface arg1) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
//    org.apache.hadoop.thirdparty.protobuf.ProtocolStringList getReservedNameList();
    org.apache.hadoop.thirdparty.protobuf.Internal.BooleanList emptyBooleanList();
    int hashEnumList(java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.Internal.EnumLite> arg0);
    DescriptorInterface getDescriptorForType();
    <M> M parseWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, CodedInputStreamInterface arg1, ExtensionRegistryLiteInterface arg2) throws java.io.IOException;
    void writeDelimitedTo(java.io.OutputStream arg0) throws java.io.IOException;
    DescriptorInterface getDescriptor();
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder toBuilder();
    java.lang.reflect.Method getMethodOrDie(java.lang.Class arg0, java.lang.String arg1, java.lang.Class... arg2);
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ExtensionRangeOrBuilder getExtensionRangeOrBuilder(int arg0);
    <V> void serializeIntegerMapTo(CodedOutputStreamInterface arg0, MapFieldInterface<java.lang.Integer, V> arg1, MapEntryInterface<java.lang.Integer, V> arg2, int arg3) throws java.io.IOException;
    DescriptorProtoInterface getDefaultInstance();
    org.apache.hadoop.thirdparty.protobuf.Internal.LongList mutableCopy(org.apache.hadoop.thirdparty.protobuf.Internal.LongList arg0);
    DescriptorProtoInterface parseFrom(CodedInputStreamInterface arg0, ExtensionRegistryLiteInterface arg1) throws java.io.IOException;
    int hashMapField(java.lang.Object arg0);
    org.apache.hadoop.thirdparty.protobuf.Internal.IntList newIntList();
    <M> M parseWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, java.io.InputStream arg1) throws java.io.IOException;
    boolean compareFields(java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg0, java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg1);
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.OneofDescriptorProtoOrBuilder getOneofDeclOrBuilder(int arg0);
    FieldAccessorTableInterface internalGetFieldAccessorTable();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ExtensionRangeOrBuilder> getExtensionRangeOrBuilderList();
    UninitializedMessageExceptionInterface newUninitializedMessageException();
    UnknownFieldSetInterface getUnknownFields();
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProtoOrBuilder getFieldOrBuilder(int arg0);
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto.ExtensionRange> getExtensionRangeList();
//    org.apache.hadoop.thirdparty.protobuf.MessageLite.Builder toBuilder();
    int getEnumTypeCount();
    FieldDescriptorInterface getOneofFieldDescriptor(OneofDescriptorInterface arg0);
    MessageOptionsInterface getOptions();
    DescriptorProtoInterface parseFrom(byte[] arg0) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.OneofDescriptorProto> getOneofDeclList();
//    org.apache.hadoop.thirdparty.protobuf.Message getDefaultInstanceForType();
    ReservedRangeInterface getReservedRange(int arg0);
    org.apache.hadoop.thirdparty.protobuf.Internal.LongList emptyLongList();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProtoOrBuilder> getNestedTypeOrBuilderList();
    DescriptorProtoInterface parseFrom(ByteStringInterface arg0, ExtensionRegistryLiteInterface arg1) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
    boolean hasField(FieldDescriptorInterface arg0);
    int hashFields(int arg0, java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg1);
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder newBuilderForType(org.apache.hadoop.thirdparty.protobuf.GeneratedMessageV3.BuilderParent arg0);
    int getExtensionRangeCount();
    <M> M parseWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, CodedInputStreamInterface arg1) throws java.io.IOException;
    <T> void addAll(java.lang.Iterable<T> arg0, java.util.Collection<? super T> arg1);
    org.apache.hadoop.thirdparty.protobuf.Internal.DoubleList mutableCopy(org.apache.hadoop.thirdparty.protobuf.Internal.DoubleList arg0);
    org.apache.hadoop.thirdparty.protobuf.Internal.LongList newLongList();
    <MessageType, T> ExtensionInterface<MessageType, T> checkNotLite(ExtensionLiteInterface<MessageType, T> arg0);
    <M> M parseWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, java.io.InputStream arg1, ExtensionRegistryLiteInterface arg2) throws java.io.IOException;
//    DescriptorProtoInterface getDefaultInstanceForType();
    java.lang.Object invokeOrDie(java.lang.reflect.Method arg0, java.lang.Object arg1, java.lang.Object... arg2);
    boolean hasOneof(OneofDescriptorInterface arg0);
    org.apache.hadoop.thirdparty.protobuf.Internal.FloatList emptyFloatList();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.OneofDescriptorProtoOrBuilder> getOneofDeclOrBuilderList();
    java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProtoOrBuilder> getFieldOrBuilderList();
    MapFieldInterface internalGetMapField(int arg0);
    void writeString(CodedOutputStreamInterface arg0, int arg1, java.lang.Object arg2) throws java.io.IOException;
    int hashEnum(org.apache.hadoop.thirdparty.protobuf.Internal.EnumLite arg0);
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder newBuilderForType(org.apache.hadoop.thirdparty.protobuf.AbstractMessage.BuilderParent arg0);
    boolean parseUnknownField(CodedInputStreamInterface arg0, BuilderInterface arg1, ExtensionRegistryLiteInterface arg2, int arg3) throws java.io.IOException;
    org.apache.hadoop.thirdparty.protobuf.Internal.FloatList newFloatList();
    ByteStringInterface getNameBytes();
    org.apache.hadoop.thirdparty.protobuf.Internal.FloatList mutableCopy(org.apache.hadoop.thirdparty.protobuf.Internal.FloatList arg0);
    DescriptorProtoInterface parseFrom(java.nio.ByteBuffer arg0) throws org.apache.hadoop.thirdparty.protobuf.InvalidProtocolBufferException;
    java.util.List<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.FieldDescriptorProto> getFieldList();
    ByteStringInterface toByteString(java.lang.Object arg0);
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProtoOrBuilder getNestedTypeOrBuilder(int arg0);
    <K, V> void serializeMapTo(CodedOutputStreamInterface arg0, java.util.Map<K, V> arg1, MapEntryInterface<K, V> arg2, int arg3) throws java.io.IOException;
    java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> getAllFieldsRaw();
    org.apache.hadoop.thirdparty.protobuf.Parser<org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.DescriptorProto> parser();
    FieldDescriptorProtoInterface getField(int arg0);
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder newBuilderForType();
    int hashCode();
    <M> M parseDelimitedWithIOException(org.apache.hadoop.thirdparty.protobuf.Parser<M> arg0, java.io.InputStream arg1) throws java.io.IOException;
    java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> getAllFieldsMutable(boolean arg0);
    java.lang.Object getRepeatedField(FieldDescriptorInterface arg0, int arg1);
    java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> getAllFields();
    int hashLong(long arg0);
    java.lang.String getSerializingExceptionMessage(java.lang.String arg0);
    org.apache.hadoop.thirdparty.protobuf.DescriptorProtos.EnumDescriptorProtoOrBuilder getEnumTypeOrBuilder(int arg0);
    int getReservedNameCount();
    int getOneofDeclCount();
    DescriptorProtoInterface getNestedType(int arg0);
    boolean canUseUnsafe();
}