package org.apache.hadoop.hdfs.remoteProxies;

public interface MapEntryInterface<K, V> {
    K getKey();
    org.apache.hadoop.thirdparty.protobuf.MessageLite.Builder newBuilderForType();
    org.apache.hadoop.thirdparty.protobuf.Parser<? extends org.apache.hadoop.thirdparty.protobuf.Message> getParserForType();
    void writeTo(java.io.OutputStream arg0) throws java.io.IOException;
    boolean hasOneof(OneofDescriptorInterface arg0);
    int hashBoolean(boolean arg0);
    void checkByteStringIsUtf8(ByteStringInterface arg0) throws java.lang.IllegalArgumentException;
    int hashEnum(org.apache.hadoop.thirdparty.protobuf.Internal.EnumLite arg0);
    int getSerializedSize();
    java.util.Map convertMapEntryListToMap(java.util.List arg0);
    int hashCode();
    int hashLong(long arg0);
    FieldDescriptorInterface getOneofFieldDescriptor(OneofDescriptorInterface arg0);
    UninitializedMessageExceptionInterface newUninitializedMessageException();
    boolean compareFields(java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg0, java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg1);
    int hashFields(int arg0, java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> arg1);
    java.lang.Object getField(FieldDescriptorInterface arg0);
    int getMemoizedSerializedSize();
    java.util.Map<org.apache.hadoop.thirdparty.protobuf.Descriptors.FieldDescriptor, java.lang.Object> getAllFields();
    boolean equals(java.lang.Object arg0);
//    org.apache.hadoop.thirdparty.protobuf.Parser<org.apache.hadoop.thirdparty.protobuf.MapEntry<K, V>> getParserForType();
//    BuilderInterface<K, V> newBuilderForType();
    <V> boolean isInitialized(MetadataInterface arg0, V arg1);
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder newBuilderForType();
    boolean isInitialized();
    void writeDelimitedTo(java.io.OutputStream arg0) throws java.io.IOException;
    java.util.List<java.lang.String> findInitializationErrors();
    boolean hasField(FieldDescriptorInterface arg0);
    org.apache.hadoop.thirdparty.protobuf.Message getDefaultInstanceForType();
    int hashMapField(java.lang.Object arg0);
    <T> void addAll(java.lang.Iterable<T> arg0, java.util.Collection<? super T> arg1);
    java.lang.String getInitializationErrorString();
    java.lang.Object getRepeatedField(FieldDescriptorInterface arg0, int arg1);
    MetadataInterface<K, V> getMetadata();
    ByteStringInterface toByteString(java.lang.Object arg0);
    void setMemoizedSerializedSize(int arg0);
    <K, V> MapEntryInterface<K, V> newDefaultInstance(DescriptorInterface arg0, org.apache.hadoop.thirdparty.protobuf.WireFormat.FieldType arg1, K arg2, org.apache.hadoop.thirdparty.protobuf.WireFormat.FieldType arg3, V arg4);
//    org.apache.hadoop.thirdparty.protobuf.Message.Builder newBuilderForType(org.apache.hadoop.thirdparty.protobuf.AbstractMessage.BuilderParent arg0);
    org.apache.hadoop.thirdparty.protobuf.Message.Builder toBuilder();
    void writeTo(CodedOutputStreamInterface arg0) throws java.io.IOException;
    int getRepeatedFieldCount(FieldDescriptorInterface arg0);
    byte[] toByteArray();
//    org.apache.hadoop.thirdparty.protobuf.MessageLite.Builder toBuilder();
    DescriptorInterface getDescriptorForType();
    boolean compareBytes(java.lang.Object arg0, java.lang.Object arg1);
//    org.apache.hadoop.thirdparty.protobuf.MessageLite getDefaultInstanceForType();
    V getValue();
//    org.apache.hadoop.thirdparty.protobuf.Parser<? extends org.apache.hadoop.thirdparty.protobuf.MessageLite> getParserForType();
    boolean compareMapField(java.lang.Object arg0, java.lang.Object arg1);
//    BuilderInterface<K, V> toBuilder();
//    MapEntryInterface<K, V> getDefaultInstanceForType();
    UnknownFieldSetInterface getUnknownFields();
    <T> void addAll(java.lang.Iterable<T> arg0, java.util.List<? super T> arg1);
    void checkFieldDescriptor(FieldDescriptorInterface arg0);
    ByteStringInterface toByteString();
    java.lang.String toString();
    int hashEnumList(java.util.List<? extends org.apache.hadoop.thirdparty.protobuf.Internal.EnumLite> arg0);
    java.lang.String getSerializingExceptionMessage(java.lang.String arg0);
}