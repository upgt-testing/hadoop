package org.apache.hadoop.hdfs.remoteProxies;

public interface FSDirectoryInterface {
    FSEditLogInterface getEditLog();
    void verifyMaxComponentLength(byte[] arg0, java.lang.String arg1) throws org.apache.hadoop.hdfs.protocol.FSLimitException.PathComponentTooLongException;
    long removeLastINode(INodesInPathInterface arg0);
    INodeDirectoryInterface createRoot(FSNamesystemInterface arg0);
    void updateCountForQuota();
    void checkPermission(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, boolean arg2, org.apache.hadoop.fs.permission.FsAction arg3, org.apache.hadoop.fs.permission.FsAction arg4, org.apache.hadoop.fs.permission.FsAction arg5, org.apache.hadoop.fs.permission.FsAction arg6) throws org.apache.hadoop.security.AccessControlException;
    boolean shouldSkipQuotaChecks();
    INodeInterface getINode(java.lang.String arg0) throws org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    boolean isReservedName(byte[][] arg0);
    boolean isExactReservedName(byte[][] arg0);
    boolean isPermissionEnabled();
    INodesInPathInterface resolvePath(FSPermissionCheckerInterface arg0, java.lang.String arg1, org.apache.hadoop.hdfs.server.namenode.FSDirectory.DirOp arg2) throws org.apache.hadoop.fs.UnresolvedLinkException, java.io.FileNotFoundException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    boolean isPosixAclInheritanceEnabled();
    void disableQuotaChecks();
    void verifyQuota(INodesInPathInterface arg0, int arg1, QuotaCountsInterface arg2, INodeInterface arg3) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    java.lang.String setProtectedDirectories(java.lang.String arg0);
    void addYieldCount(long arg0);
    java.util.SortedSet<java.lang.String> parseProtectedDirectories(ConfigurationInterface arg0);
    void markNameCacheInitialized();
    boolean isNonEmptyDirectory(INodesInPathInterface arg0);
    int getWriteHoldCount();
    void updateCount(INodesInPathInterface arg0, long arg1, long arg2, short arg3, short arg4, boolean arg5) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    java.util.SortedSet<java.lang.String> getProtectedDirectories();
    void shutdown();
    INodeInterface getINode(java.lang.String arg0, org.apache.hadoop.hdfs.server.namenode.FSDirectory.DirOp arg1) throws org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    void verifyINodeName(byte[] arg0) throws org.apache.hadoop.HadoopIllegalArgumentException;
    boolean isAclsEnabled();
    void checkOwner(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1) throws org.apache.hadoop.security.AccessControlException, java.io.FileNotFoundException;
    boolean isReservedRawName(byte[][] arg0);
    void readLock();
    int getContentCountLimit();
    void reset();
    boolean isQuotaByStorageTypeEnabled();
    boolean isReservedName(java.lang.String arg0);
    void updateCount(INodesInPathInterface arg0, long arg1, long arg2, short arg3, boolean arg4) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    void close() throws java.io.IOException;
    void updateSpaceForCompleteBlock(BlockInfoInterface arg0, INodesInPathInterface arg1) throws java.io.IOException;
    boolean hasReadLock();
    void checkTraverse(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, boolean arg2) throws org.apache.hadoop.security.AccessControlException, org.apache.hadoop.hdfs.protocol.UnresolvedPathException, org.apache.hadoop.fs.ParentNotDirectoryException;
    void checkTraverse(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, org.apache.hadoop.hdfs.server.namenode.FSDirectory.DirOp arg2) throws org.apache.hadoop.security.AccessControlException, org.apache.hadoop.hdfs.protocol.UnresolvedPathException, org.apache.hadoop.fs.ParentNotDirectoryException;
    long getYieldCount();
    void enableQuotaChecks();
    void checkPathAccess(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, org.apache.hadoop.fs.permission.FsAction arg2) throws org.apache.hadoop.security.AccessControlException;
    void updateCountForQuota(int arg0);
    INodeAttributeProviderInterface getUserFilteredAttributeProvider(UserGroupInformationInterface arg0);
    boolean isReservedRawName(java.lang.String arg0);
    INodeMapInterface getINodeMap();
    void setINodeAttributeProvider(INodeAttributeProviderInterface arg0);
    boolean isXattrsEnabled();
    int getXattrMaxSize();
    byte[][] resolveComponents(byte[][] arg0, FSDirectoryInterface arg1) throws java.io.FileNotFoundException;
    void resetLastInodeId(long arg0) throws java.io.IOException;
    FileStatusInterface getAuditFileInfo(INodesInPathInterface arg0) throws java.io.IOException;
    byte[][] getPathComponents(INodeInterface arg0);
    BlockManagerInterface getBlockManager();
    void addToInodeMap(INodeInterface arg0);
    long totalInodes();
    void updateCount(INodesInPathInterface arg0, QuotaDeltaInterface arg1, boolean arg2) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    void updateSpaceConsumed(INodesInPathInterface arg0, long arg1, long arg2, short arg3) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException, java.io.FileNotFoundException, org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException;
    java.lang.String normalizePath(java.lang.String arg0);
    long getLastInodeId();
    void readUnlock();
    KeyProviderCryptoExtensionInterface getProvider();
    void addEncryptionZone(INodeWithAdditionalFieldsInterface arg0, XAttrFeatureInterface arg1);
    boolean isValidToCreate(java.lang.String arg0, INodesInPathInterface arg1) throws org.apache.hadoop.hdfs.protocol.SnapshotAccessControlException;
    INodesInPathInterface getINodesInPath(java.lang.String arg0, org.apache.hadoop.hdfs.server.namenode.FSDirectory.DirOp arg1) throws org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    void writeLock();
    void removeFromInodeMap(java.util.List<? extends org.apache.hadoop.hdfs.server.namenode.INode> arg0);
    java.lang.String resolvePath(java.lang.String arg0, FSDirectoryInterface arg1) throws java.io.FileNotFoundException;
    int getLsLimit();
    INodeDirectoryInterface getRoot();
    EnumCountersInterface<org.apache.hadoop.fs.StorageType> getStorageTypeDeltas(byte arg0, long arg1, short arg2, short arg3);
    boolean hasWriteLock();
    FSPermissionCheckerInterface getPermissionChecker() throws org.apache.hadoop.security.AccessControlException;
    BlockStoragePolicySuiteInterface getBlockStoragePolicySuite();
    void resetLastInodeIdWithoutChecking(long arg0);
    FSNamesystemInterface getFSNamesystem();
    boolean isAccessTimeSupported();
    void checkUnreadableBySuperuser(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1) throws java.io.IOException;
    INodeInterface getInode(long arg0);
    java.util.Collection<java.lang.String> normalizePaths(java.util.Collection<java.lang.String> arg0, java.lang.String arg1);
    int getListLimit();
    boolean isPermissionContentSummarySubAccess();
    long getContentSleepMicroSec();
    void cacheName(INodeInterface arg0);
    void updateCountForDelete(INodeInterface arg0, INodesInPathInterface arg1);
    void updateCountNoQuotaCheck(INodesInPathInterface arg0, int arg1, QuotaCountsInterface arg2);
    void updateReplicationFactor(java.util.Collection<org.apache.hadoop.hdfs.server.namenode.INode.BlocksMapUpdateInfo.UpdatedReplicationInfo> arg0);
    void checkPermission(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, boolean arg2, org.apache.hadoop.fs.permission.FsAction arg3, org.apache.hadoop.fs.permission.FsAction arg4, org.apache.hadoop.fs.permission.FsAction arg5, org.apache.hadoop.fs.permission.FsAction arg6, boolean arg7) throws org.apache.hadoop.security.AccessControlException;
    void copyINodeDefaultAcl(INodeInterface arg0, FsPermissionInterface arg1);
    INodesInPathInterface resolvePath(FSPermissionCheckerInterface arg0, java.lang.String arg1, long arg2) throws org.apache.hadoop.fs.UnresolvedLinkException, java.io.FileNotFoundException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    boolean isProtectedSubDirectoriesEnable();
    INodeInterface getINode4Write(java.lang.String arg0) throws org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.security.AccessControlException, java.io.FileNotFoundException, org.apache.hadoop.fs.ParentNotDirectoryException;
    INodeInterface resolveLastINode(INodesInPathInterface arg0) throws java.io.FileNotFoundException;
    java.util.SortedSet<java.lang.String> parseProtectedDirectories(java.util.Collection<java.lang.String> arg0);
    int getInodeXAttrsLimit();
    void setPosixAclInheritanceEnabled(boolean arg0);
    void verifyMaxDirItems(INodeDirectoryInterface arg0, java.lang.String arg1) throws org.apache.hadoop.hdfs.protocol.FSLimitException.MaxDirectoryItemsExceededException;
    void writeUnlock();
    boolean isUserBypassingExtAttrProvider(java.lang.String arg0);
    boolean isReservedInodesName(java.lang.String arg0);
    void verifyParentDir(INodesInPathInterface arg0) throws java.io.FileNotFoundException, org.apache.hadoop.fs.ParentNotDirectoryException;
    INodeInterface getINode4DotSnapshot(INodesInPathInterface arg0) throws org.apache.hadoop.fs.UnresolvedLinkException;
    void addStoragePolicySatisfier(INodeWithAdditionalFieldsInterface arg0, XAttrFeatureInterface arg1);
    int getInodeMapSize();
    void checkParentAccess(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, org.apache.hadoop.fs.permission.FsAction arg2) throws org.apache.hadoop.security.AccessControlException;
    void createReservedStatuses(long arg0);
    boolean isReservedName(INodeInterface arg0);
    void checkAncestorAccess(FSPermissionCheckerInterface arg0, INodesInPathInterface arg1, org.apache.hadoop.fs.permission.FsAction arg2) throws org.apache.hadoop.security.AccessControlException;
    java.util.SortedSet<java.lang.String> parseProtectedDirectories(java.lang.String arg0);
    void unprotectedUpdateCount(INodesInPathInterface arg0, int arg1, QuotaCountsInterface arg2);
    INodesInPathInterface unprotectedResolvePath(java.lang.String arg0) throws java.io.FileNotFoundException;
    INodesInPathInterface addINode(INodesInPathInterface arg0, INodeInterface arg1, FsPermissionInterface arg2) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException, org.apache.hadoop.fs.UnresolvedLinkException;
    byte[][] constructRemainingPath(byte[][] arg0, byte[][] arg1, int arg2);
    INodesInPathInterface addLastINodeNoQuotaCheck(INodesInPathInterface arg0, INodeInterface arg1);
    org.apache.hadoop.hdfs.server.namenode.INodeAttributes getAttributes(INodesInPathInterface arg0) throws java.io.IOException;
    boolean isExactReservedName(java.lang.String arg0);
    long getAccessTimePrecision();
    FSPermissionCheckerInterface getPermissionChecker(java.lang.String arg0, java.lang.String arg1, UserGroupInformationInterface arg2) throws org.apache.hadoop.security.AccessControlException;
    void initUsersToBypassExtProvider(ConfigurationInterface arg0);
    INodesInPathInterface getINodesInPath(byte[][] arg0, org.apache.hadoop.hdfs.server.namenode.FSDirectory.DirOp arg1) throws org.apache.hadoop.fs.UnresolvedLinkException, org.apache.hadoop.security.AccessControlException, org.apache.hadoop.fs.ParentNotDirectoryException;
    byte[][] resolveDotInodesPath(byte[][] arg0, FSDirectoryInterface arg1) throws java.io.FileNotFoundException;
    void updateCount(INodesInPathInterface arg0, int arg1, QuotaCountsInterface arg2, boolean arg3) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    INodesInPathInterface addLastINode(INodesInPathInterface arg0, INodeInterface arg1, FsPermissionInterface arg2, boolean arg3) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    org.apache.hadoop.hdfs.protocol.HdfsFileStatus[] getReservedStatuses();
    int getReadHoldCount();
    long allocateNewInodeId();
    void addRootDirToEncryptionZone(XAttrFeatureInterface arg0);
}