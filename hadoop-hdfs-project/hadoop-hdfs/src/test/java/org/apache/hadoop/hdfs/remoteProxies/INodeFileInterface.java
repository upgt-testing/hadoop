package org.apache.hadoop.hdfs.remoteProxies;

public interface INodeFileInterface {
    java.lang.StringBuffer dumpTreeRecursively();
    INodeReferenceInterface getParentReference();
    short getFileReplication(int arg0);
    AclFeatureInterface getAclFeature(int arg0);
    long computeFileSize(boolean arg0, boolean arg1);
    byte getErasureCodingPolicyID();
    java.lang.String getLocalName();
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0, boolean arg1);
    long computeFileSize();
    boolean isWithSnapshot();
    org.apache.hadoop.hdfs.server.namenode.INodeAttributes getSnapshotINode(int arg0);
    INodeFileInterface valueOf(INodeInterface arg0, java.lang.String arg1, boolean arg2) throws java.io.FileNotFoundException;
    XAttrFeatureInterface getXAttrFeature(int arg0);
    BlockInfoInterface getPenultimateBlock();
    boolean isUnderConstruction();
    byte[] getLocalNameBytes();
    FileWithSnapshotFeatureInterface getFileWithSnapshotFeature();
    boolean isInCurrentState();
    INodeInterface setModificationTime(long arg0, int arg1);
    QuotaCountsInterface storagespaceConsumedStriped();
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0, byte arg1, boolean arg2, int arg3);
    boolean isLastReference();
    java.lang.String[] getPathNames(java.lang.String arg0);
    long computeFileSize(int arg0);
    BlockInfoInterface[] getBlocks();
    void setFileReplication(short arg0);
    long getModificationTime(int arg0);
    int compareTo(byte[] arg0);
    byte[][] getPathComponents();
    byte[][] getPathComponents(java.lang.String arg0);
    boolean isStriped();
    java.lang.String toDetailString();
    void assertAllBlocksComplete(int arg0, short arg1);
    byte[] getKey();
    long getId();
    BlockInfoInterface[] getBlocks(int arg0);
    void collectBlocksBeyondSnapshot(BlockInfoInterface[] arg0, BlocksMapUpdateInfoInterface arg1);
    long getAccessTime(int arg0);
    INodeInterface removeXAttrFeature(int arg0);
    java.lang.String getUserName(int arg0);
    void dumpTreeRecursively(java.io.PrintStream arg0);
    boolean isSetStoragePolicy();
//    org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes getSnapshotINode(int arg0);
    java.lang.String getName();
    INodeFileInterface toUnderConstruction(java.lang.String arg0, java.lang.String arg1);
    void destroyAndCollectBlocks(ReclaimContextInterface arg0);
    PermissionStatusInterface getPermissionStatus();
    INodeInterface setAccessTime(long arg0, int arg1, boolean arg2);
    long getPreferredBlockSize();
    java.util.Set<org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo> getSnapshotBlocksToRetain(int arg0);
    org.apache.hadoop.hdfs.server.namenode.INode.Feature[] getFeatures();
    long getDiskSpaceQuota(ContentCountsInterface arg0, FileWithSnapshotFeatureInterface arg1, int arg2);
    INodeInterface removeAclFeature(int arg0);
    boolean isReference();
    INodeFileInterface setFileReplication(short arg0, int arg1) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    void clonePermissionStatus(INodeWithAdditionalFieldsInterface arg0);
    INodeDirectoryInterface getParent();
    long getAccessTime();
    void computeQuotaDeltaForTruncate(long arg0, BlockStoragePolicyInterface arg1, QuotaCountsInterface arg2);
    QuotaCountsInterface getQuotaCounts();
    boolean isDeleted();
    void setBlock(int arg0, BlockInfoInterface arg1);
    long getHeaderLong();
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0);
    boolean isInLatestSnapshot(int arg0);
    void setLastBlock(BlockInfoInterface arg0);
//    void updatePermissionStatus(org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.PermissionStatusFormat arg0, long arg1);
    java.lang.String getParentString();
    void setUser(java.lang.String arg0);
    byte getLocalStoragePolicyID();
    ContentSummaryInterface computeAndConvertContentSummary(int arg0, ContentSummaryComputationContextInterface arg1) throws org.apache.hadoop.security.AccessControlException;
    long collectBlocksBeyondMax(long arg0, BlocksMapUpdateInfoInterface arg1, java.util.Set<org.apache.hadoop.hdfs.server.blockmanagement.BlockInfo> arg2);
    void addBlock(BlockInfoInterface arg0);
    QuotaCountsInterface storagespaceConsumedContiguous(BlockStoragePolicyInterface arg0);
    void removeAclFeature();
    INodeSymlinkInterface asSymlink();
    BlockInfoInterface getLastBlock();
    void setLocalName(byte[] arg0);
    boolean equals(java.lang.Object arg0);
    void cloneModificationTime(INodeWithAdditionalFieldsInterface arg0);
    void dumpTreeRecursively(java.io.PrintWriter arg0, java.lang.StringBuilder arg1, int arg2);
    PermissionStatusInterface getPermissionStatus(int arg0);
    INodeInterface setGroup(java.lang.String arg0, int arg1);
    INodeInterface setPermission(FsPermissionInterface arg0, int arg1);
    void addFeature(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    void addSpaceConsumed(QuotaCountsInterface arg0);
    void updateRemovedUnderConstructionFiles(ReclaimContextInterface arg0);
    boolean shouldRecordInSrcSnapshot(int arg0);
    long getModificationTime();
    void checkAbsolutePath(java.lang.String arg0);
    void setParent(INodeDirectoryInterface arg0);
    boolean isDirectory();
    org.apache.hadoop.hdfs.protocol.BlockType getBlockType();
    java.lang.String getGroupName(int arg0);
    void addXAttrFeature(XAttrFeatureInterface arg0);
    java.lang.String getGroupName();
    boolean isBlockInLatestSnapshot(BlockInfoInterface arg0);
    java.lang.String checkBlockComplete(BlockInfoInterface[] arg0, int arg1, int arg2, short arg3);
    QuotaCountsInterface computeQuotaUsageWithStriped(BlockStoragePolicyInterface arg0, QuotaCountsInterface arg1);
    void clearFile(ReclaimContextInterface arg0);
    long getPermissionLong();
    INodeDirectoryInterface asDirectory();
    void cleanSubtree(ReclaimContextInterface arg0, int arg1, int arg2);
    <T> T getFeature(java.lang.Class<? extends org.apache.hadoop.hdfs.server.namenode.INode.Feature> arg0);
    FileUnderConstructionFeatureInterface getFileUnderConstructionFeature();
    INodeInterface updateModificationTime(long arg0, int arg1);
    void concatBlocks(INodeFileInterface[] arg0, BlockManagerInterface arg1);
    java.lang.String getUserName();
    boolean isFile();
    void recordModification(int arg0, boolean arg1);
    INodeInterface addAclFeature(AclFeatureInterface arg0, int arg1);
    void toCompleteFile(long arg0, int arg1, short arg2);
    void throwFeatureNotFoundException(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    java.lang.String toString();
    long computeFileSizeNotIncludingLastUcBlock();
    void setStoragePolicyID(byte arg0, int arg1) throws org.apache.hadoop.hdfs.protocol.QuotaExceededException;
    FsPermissionInterface getFsPermission(int arg0);
//    K getKey();
    void convertLastBlockToUC(BlockInfoInterface arg0, DatanodeStorageInfoInterface[] arg1) throws java.io.IOException;
    void removeXAttrFeature();
    void setStoragePolicyID(byte arg0);
    AclFeatureInterface getAclFeature();
    INodeFileInterface valueOf(INodeInterface arg0, java.lang.String arg1) throws java.io.FileNotFoundException;
    XAttrFeatureInterface getXAttrFeature();
    ContentSummaryComputationContextInterface computeContentSummary(int arg0, ContentSummaryComputationContextInterface arg1);
    short getPreferredBlockReplication();
    short getFsPermissionShort();
    QuotaCountsInterface storagespaceConsumed(BlockStoragePolicyInterface arg0);
    void setNext(org.apache.hadoop.util.LightWeightGSet.LinkedElement arg0);
    void setGroup(java.lang.String arg0);
    boolean isRoot();
    FsPermissionInterface getFsPermission();
    int hashCode();
    short getFileReplication();
    void clearBlocks();
    FileDiffListInterface getDiffs();
    byte getStoragePolicyID();
    boolean isAncestorDirectory(INodeDirectoryInterface arg0);
    void setModificationTime(long arg0);
    void setAccessTime(long arg0);
    INodeInterface addXAttrFeature(XAttrFeatureInterface arg0, int arg1);
    void setPermission(FsPermissionInterface arg0);
    org.apache.hadoop.util.LightWeightGSet.LinkedElement getNext();
    FileWithSnapshotFeatureInterface addSnapshotFeature(FileDiffListInterface arg0);
    void recordModification(int arg0);
    void setParentReference(INodeReferenceInterface arg0);
    java.lang.String getObjectString();
    void setBlocks(BlockInfoInterface[] arg0);
    void clear();
    ContentSummaryInterface computeContentSummary(BlockStoragePolicySuiteInterface arg0) throws org.apache.hadoop.security.AccessControlException;
    INodeFileInterface asFile();
    INodeReferenceInterface asReference();
    boolean metadataEquals(org.apache.hadoop.hdfs.server.namenode.INodeFileAttributes arg0);
    boolean isQuotaSet();
    boolean isSymlink();
    boolean isValidAbsolutePath(java.lang.String arg0);
    byte getStoragePolicyIDForQuota(byte arg0);
    java.lang.String getFullPathName();
    INodeInterface setUser(java.lang.String arg0, int arg1);
    int numBlocks();
    void truncateBlocksTo(int arg0);
    void addAclFeature(AclFeatureInterface arg0);
    void removeFeature(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    BlockInfoInterface removeLastBlock(BlockInterface arg0);
}