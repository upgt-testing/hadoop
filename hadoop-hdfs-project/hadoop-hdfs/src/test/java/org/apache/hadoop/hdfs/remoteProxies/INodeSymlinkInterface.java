package org.apache.hadoop.hdfs.remoteProxies;

public interface INodeSymlinkInterface {
    PermissionStatusInterface getPermissionStatus(int arg0);
    void throwFeatureNotFoundException(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    INodeDirectoryInterface getParent();
    INodeSymlinkInterface asSymlink();
    void recordModification(int arg0);
    boolean isInLatestSnapshot(int arg0);
    long getAccessTime();
    byte[] getLocalNameBytes();
    boolean isValidAbsolutePath(java.lang.String arg0);
    int compareTo(byte[] arg0);
    byte[] getKey();
    void destroyAndCollectBlocks(ReclaimContextInterface arg0);
    java.lang.String getSymlinkString();
    java.lang.StringBuffer dumpTreeRecursively();
    java.lang.String[] getPathNames(java.lang.String arg0);
    byte getLocalStoragePolicyID();
    FsPermissionInterface getFsPermission(int arg0);
    org.apache.hadoop.util.LightWeightGSet.LinkedElement getNext();
    INodeInterface setPermission(FsPermissionInterface arg0, int arg1);
    void addXAttrFeature(XAttrFeatureInterface arg0);
//    void updatePermissionStatus(org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.PermissionStatusFormat arg0, long arg1);
    XAttrFeatureInterface getXAttrFeature();
    org.apache.hadoop.hdfs.server.namenode.INodeAttributes getSnapshotINode(int arg0);
    void removeFeature(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    boolean isReference();
    void addSpaceConsumed(QuotaCountsInterface arg0);
    boolean isSymlink();
    void setGroup(java.lang.String arg0);
    ContentSummaryComputationContextInterface computeContentSummary(int arg0, ContentSummaryComputationContextInterface arg1);
    boolean isQuotaSet();
    java.lang.String getFullPathName();
    INodeInterface addAclFeature(AclFeatureInterface arg0, int arg1);
    boolean shouldRecordInSrcSnapshot(int arg0);
    boolean isFile();
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0);
    void setParentReference(INodeReferenceInterface arg0);
    PermissionStatusInterface getPermissionStatus();
    void clonePermissionStatus(INodeWithAdditionalFieldsInterface arg0);
    XAttrFeatureInterface getXAttrFeature(int arg0);
    AclFeatureInterface getAclFeature();
    void dumpTreeRecursively(java.io.PrintStream arg0);
    void setNext(org.apache.hadoop.util.LightWeightGSet.LinkedElement arg0);
    java.lang.String getGroupName(int arg0);
    INodeReferenceInterface asReference();
//    K getKey();
    long getModificationTime(int arg0);
    INodeInterface setAccessTime(long arg0, int arg1, boolean arg2);
    void checkAbsolutePath(java.lang.String arg0);
    void removeXAttrFeature();
    void clear();
    java.lang.String toDetailString();
    INodeInterface removeXAttrFeature(int arg0);
    void dumpTreeRecursively(java.io.PrintWriter arg0, java.lang.StringBuilder arg1, int arg2);
    java.lang.String getUserName(int arg0);
    boolean equals(java.lang.Object arg0);
    AclFeatureInterface getAclFeature(int arg0);
    boolean isAncestorDirectory(INodeDirectoryInterface arg0);
    java.lang.String getUserName();
    INodeDirectoryInterface asDirectory();
    INodeInterface addXAttrFeature(XAttrFeatureInterface arg0, int arg1);
    void setParent(INodeDirectoryInterface arg0);
    void cleanSubtree(ReclaimContextInterface arg0, int arg1, int arg2);
    boolean isDirectory();
    void setAccessTime(long arg0);
    void setLocalName(byte[] arg0);
    void setUser(java.lang.String arg0);
    INodeInterface updateModificationTime(long arg0, int arg1);
    void addFeature(org.apache.hadoop.hdfs.server.namenode.INode.Feature arg0);
    boolean isSetStoragePolicy();
    INodeInterface setUser(java.lang.String arg0, int arg1);
    java.lang.String getGroupName();
    org.apache.hadoop.hdfs.server.namenode.INode.Feature[] getFeatures();
    byte[][] getPathComponents(java.lang.String arg0);
    boolean isLastReference();
    ContentSummaryInterface computeAndConvertContentSummary(int arg0, ContentSummaryComputationContextInterface arg1) throws org.apache.hadoop.security.AccessControlException;
    java.lang.String getObjectString();
    java.lang.String getLocalName();
    QuotaCountsInterface getQuotaCounts();
    java.lang.String toString();
    INodeReferenceInterface getParentReference();
    void setPermission(FsPermissionInterface arg0);
    byte getStoragePolicyIDForQuota(byte arg0);
    byte[][] getPathComponents();
    void setModificationTime(long arg0);
    void addAclFeature(AclFeatureInterface arg0);
    long getAccessTime(int arg0);
    byte getStoragePolicyID();
    int hashCode();
    INodeInterface setModificationTime(long arg0, int arg1);
    ContentSummaryInterface computeContentSummary(BlockStoragePolicySuiteInterface arg0) throws org.apache.hadoop.security.AccessControlException;
    void cloneModificationTime(INodeWithAdditionalFieldsInterface arg0);
    long getModificationTime();
    long getPermissionLong();
    INodeInterface removeAclFeature(int arg0);
    short getFsPermissionShort();
    <T> T getFeature(java.lang.Class<? extends org.apache.hadoop.hdfs.server.namenode.INode.Feature> arg0);
    INodeFileInterface asFile();
    boolean isRoot();
    java.lang.String getParentString();
    long getId();
    FsPermissionInterface getFsPermission();
    byte[] getSymlink();
    void removeAclFeature();
    INodeInterface setGroup(java.lang.String arg0, int arg1);
    boolean isInCurrentState();
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0, byte arg1, boolean arg2, int arg3);
    QuotaCountsInterface computeQuotaUsage(BlockStoragePolicySuiteInterface arg0, boolean arg1);
    boolean isDeleted();
}